그래서 1만큼 틀려서 적절히 해보고 마지막에 보통 아담의 이제
아류작들이나 아니면 아담의 어떤 아담에도 이제 러닝 레이트를 조절
할 수가 있거든요.
저희가 상수들을 조절할 수 있거든요.
상수들을 조절을 해서 조금 더 뭔가 튜닝을 끝까지 한번 해본다던가
이정도만 하는 추세인 것 같아요.
이제는 기본적으로는 아담을 쓰면 손해볼 건 없다 이렇게 요약하면
되겠습니다.
옵티마이저는 여기까지 하고요.
넘어가기 전에 액티베이션 얘기를 살짝만 더 한번 해볼 건데요.
이 액티베이션은 시그모이드 혹은 탄젠 아크탄젠트 이걸 썼어요.
탄젠타이퍼볼리 왜냐하면 발산을 하니까 0에서 1사이 또는 마이너스
에서 1사이로 밸류를 발산하지 않게 하려고 발산하지 않게 하려고
하는 이유가 다 사실 레이어를 많이 쌓으려고 합니다.
레이어를 많이 쌓았을 때 계속 발산을 해버리니까 다 압축을 하려고
이렇게 이런 함수를 썼어요.
문제가 있어요.
뉴럴렛을 레이어를 많이 쌓아요 이게 딥이죠.
이때는 뭐 dnn이라고 불렀어요.
이 딥러닝을 dnn이라고 불렀었는데 이 dnn을 하면 딥하게 싸우면
학습이 안 돼요.
학습이 정확히는 여기가 학습이 안 돼요.
왜냐하면 사실 이게 원리가 같아요.
발산하지 말라고 밸류를 압축을 했어요.
밸류를 계속 압축을 했죠.
근데 저희가 여기서 에러를 계산해서 이 에러를 앞으로 넘겨서
얘네들 어떻게 웨이트를 업데이트 할지를 계산을 한단 말이죠.
에러도 압축이 되는 거예요.
당연히 그렇겠죠.
밸류를 팍팍팍 줄이는 행위들을 사이사이해서 했으니까
뒤로 넘어갈 때도 얘를 뭐 올려야 될까 줄여야 될까 할 때
시그월드가 영향을 줄 테니까 얼마나 업데이트를 해야 될까 영향을 줄 테니까
여기가 학습이 안 되는 거예요.
수식으로 증명을 하자면 시그모이드랑 아크탄젠트가
미분을 했을 때
0과 1 사이에 있기 때문에
0과 1 사이에 있어서 넘어갈 때마다 에러가
0과 1 사이로 밸류가 곱해져서
점점 작아지기 때문에
그런 건데 자세한 수식은 생략을 하고요.
어쨌든 개념적으로는
앞으로 가는 거 발산하지 말라고 압축한 게
학습에도 영향을 줘서 레이어를 깊게 싸우면
앞단이 학습이 안 되더라.
그래서 이 문제를
gradient가 vanishing 된다라고 정의를 했습니다.
이게 이제 딥러닝이 세상에 빵 터지기 전에
딥러닝이 안 되던 이유
수식적으로, 이론적으로 안 되던 이유 첫 번째예요.
이거를 이제 해결해야 되죠.
어떻게 해결을 했냐.
일단 첫 번째는
액티베이션 펑션을 바꿨어요.
렐루라는 걸로 바꿨습니다.
렉티파이드 리니어 유닛이라는 건데
이 함수는
시그모이드 나크탄 젠트가 아니라
이렇게 생겼어요.
음수는 그냥 다 0으로 바꿔버리고
양수는 그대로 가요.
밸루를 줄이고 이런 거 없이 그냥 그대로 가요.
그러면
유런이 이제 음수로
